{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f50c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e188ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.annotations = self.load_annotations()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and annotations\n",
    "        img_path = os.path.join(self.root, \n",
    "                                'sfrs_' + self.annotations[idx]['filename'][2], \n",
    "                                self.annotations[idx]['filename'][:-7], \n",
    "                                self.annotations[idx]['filename'])\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        target = self.annotations[idx]['annotation']\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def load_annotations(self):\n",
    "        annotations = []\n",
    "        # Parse XML files\n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for xml_file in files:\n",
    "                if xml_file.endswith(\".xml\"):\n",
    "                    tree = ET.parse(os.path.join(root, xml_file))\n",
    "                    root = tree.getroot()\n",
    "                    annotation = {\n",
    "                        'filename': root.find('filename').text,\n",
    "                        'annotation': {\n",
    "                            'boxes': [],\n",
    "                            'labels': []\n",
    "                        }\n",
    "                    }\n",
    "                    for obj in root.findall('object'):\n",
    "                        box = obj.find('bndbox')\n",
    "                        xmin = int(box.find('xmin').text)\n",
    "                        ymin = int(box.find('ymin').text)\n",
    "                        xmax = int(box.find('xmax').text)\n",
    "                        ymax = int(box.find('ymax').text)\n",
    "\n",
    "                        annotation['annotation']['boxes'].append([xmin, ymin, xmax, ymax])\n",
    "                        annotation['annotation']['labels'].append(int(obj.find('name').text))\n",
    "\n",
    "                    annotations.append(annotation)\n",
    "\n",
    "        return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fda316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbae05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(root='../data/data', transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e96ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]]), {'boxes': [[485, 284, 1947, 680]], 'labels': [1]})\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3def752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained Faster R-CNN model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1  \n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae56b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b33932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and the learning rate scheduler\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in train_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Update the learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {losses.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f11ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
